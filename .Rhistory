# -------------------------------------
# -----------------------------------
# TARGET VARIABLE "Y"
all_bd$y = as.numeric(all_bd$y=="yes")
all_bd$y = as.factor(all_bd$y)
# -----------------------------------
# PREPARED TRAINING DATASET
bd_train = all_bd[which(all_bd$data=="train"),]
bd_train = bd_train %>% select(-data)
# PREPARED TEST DATASET
bd_test = all_bd[which(all_bd=="test"),]
bd_test = bd_test %>% select(-data)
View(bd_test)
View(best_params)
# --------------------------
library(dplyr)
library(tidyr)
library(ggplot2)
library(neuralnet)
library(randomForest)
library(gbm)
library(e1071)
library(pROC)
library(caret)
library(cvTools)
# ------------------------
bdtr<- read.csv("E:\\edvancer\\business_analytics\\r_programming\\upgrad\\bank-additional\\bank-additional-full.csv",
stringsAsFactors = F,sep = ";")
bdts <- read.csv("E:\\edvancer\\business_analytics\\r_programming\\upgrad\\bank-additional\\bank-additional.csv",
stringsAsFactors = F,sep = ";")
bdtr <- bdtr %>%
mutate(data="train")
bdts <- bdts %>%
mutate(data="test")
all_bd <- rbind(bdtr,bdts)
summary(all_bd)
glimpse(all_bd)
# --------------------------------
# mode of categorical variable
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# ------------------------------
names(all_bd) # name of columns
# missing values
for (i in names(all_bd)) {
print(paste(i,":",sum(is.na(all_bd[i]))))
}
# ---------------------
# TO create Dummy Variables
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
# ------------------------
# To check Categorical variables or features
col_names<-names(all_bd[sapply(all_bd,function(x) is.character(x))])
col_names
# ----------------------------------------------------
# CATEGORICAL VARIABLES CONVERSION TO DUMMIES
#  JOB
sort(table(all_bd$job),decreasing = T)
all_bd = CreateDummies(all_bd,"job",1000)
# MARITAL
sort(table(all_bd$marital),decreasing = T)
all_bd = CreateDummies(all_bd,"marital",5000)
# EDUCATION
sort(table(all_bd$education),decreasing = T)
all_bd = CreateDummies(all_bd,"education",2500)
# DEFAULT
sort(table(all_bd$default),decreasing = T)
all_bd = CreateDummies(all_bd,"default",5000)
# HOUSING
sort(table(all_bd$housing),decreasing = T)
all_bd = CreateDummies(all_bd,"housing",5000)
# LOAN
sort(table(all_bd$loan),decreasing = T)
all_bd = CreateDummies(all_bd,"loan",5000)
# CONTACT
sort(table(all_bd$contact),decreasing = T)
all_bd = CreateDummies(all_bd,"contact",0)
# MONTH
sort(table(all_bd$month),decreasing = T)
all_bd = CreateDummies(all_bd,"month",100)
# DAY OF WEEK
sort(table(all_bd$day_of_week),decreasing = T)
all_bd = CreateDummies(all_bd,"day_of_week",0)
# POUTCOME
sort(table(all_bd$poutcome),decreasing = T)
all_bd = CreateDummies(all_bd,"poutcome",1000)
# ------------------------
cor_mat <- round(cor(all_bd[c(1:10)]),2)
library(reshape2)
melted_cormat = melt(cor_mat)
ggplot(melted_cormat,aes(x=Var1,y=Var2,fill=value)) + geom_tile()
# -------------------------------------
# AGE - NUMERIC
hist(all_bd$age)
boxplot(all_bd$age)
# DURATION - NUMERIC
hist(log(all_bd$duration))
boxplot(log(all_bd$duration))
# -------------------------------
# CAMPAIGN - CATEGORICAL
sort(table(all_bd$campaign),decreasing = T)
all_bd = CreateDummies(all_bd,"campaign",100)
# PDAYS - CAETGORICAL
sort(table(all_bd$pdays),decreasing = T)
all_bd = CreateDummies(all_bd,"pdays",100)
# PREVIOUS - CATEGORICAL
sort(table(all_bd$previous),decreasing = T)
all_bd = CreateDummies(all_bd,"previous",100)
# -------------------------------------
View(all_bd)
# --------------------------
library(dplyr)
library(tidyr)
library(ggplot2)
library(neuralnet)
library(randomForest)
library(gbm)
library(e1071)
library(pROC)
library(caret)
library(cvTools)
# ------------------------
bdtr<- read.csv("E:\\edvancer\\business_analytics\\r_programming\\upgrad\\bank-additional\\bank-additional-full.csv",
stringsAsFactors = F,sep = ";")
bdts <- read.csv("E:\\edvancer\\business_analytics\\r_programming\\upgrad\\bank-additional\\bank-additional.csv",
stringsAsFactors = F,sep = ";")
bdtr <- bdtr %>%
mutate(data="train")
bdts <- bdts %>%
mutate(data="test")
all_bd <- rbind(bdtr,bdts)
summary(all_bd)
glimpse(all_bd)
# --------------------------------
# mode of categorical variable
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# ------------------------------
names(all_bd) # name of columns
# missing values
for (i in names(all_bd)) {
print(paste(i,":",sum(is.na(all_bd[i]))))
}
# ---------------------
# TO create Dummy Variables
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
# ------------------------
# To check Categorical variables or features
col_names<-names(all_bd[sapply(all_bd,function(x) is.character(x))])
col_names
# ----------------------------------------------------
# CATEGORICAL VARIABLES CONVERSION TO DUMMIES
#  JOB
sort(table(all_bd$job),decreasing = T)
all_bd = CreateDummies(all_bd,"job",1000)
# MARITAL
sort(table(all_bd$marital),decreasing = T)
all_bd = CreateDummies(all_bd,"marital",5000)
# EDUCATION
sort(table(all_bd$education),decreasing = T)
all_bd = CreateDummies(all_bd,"education",2500)
# DEFAULT
sort(table(all_bd$default),decreasing = T)
all_bd = CreateDummies(all_bd,"default",5000)
# HOUSING
sort(table(all_bd$housing),decreasing = T)
all_bd = CreateDummies(all_bd,"housing",5000)
# LOAN
sort(table(all_bd$loan),decreasing = T)
all_bd = CreateDummies(all_bd,"loan",5000)
# CONTACT
sort(table(all_bd$contact),decreasing = T)
all_bd = CreateDummies(all_bd,"contact",0)
# MONTH
sort(table(all_bd$month),decreasing = T)
all_bd = CreateDummies(all_bd,"month",100)
# DAY OF WEEK
sort(table(all_bd$day_of_week),decreasing = T)
all_bd = CreateDummies(all_bd,"day_of_week",0)
# POUTCOME
sort(table(all_bd$poutcome),decreasing = T)
all_bd = CreateDummies(all_bd,"poutcome",1000)
# ------------------------
cor_mat <- round(cor(all_bd[c(1:10)]),2)
library(reshape2)
melted_cormat = melt(cor_mat)
ggplot(melted_cormat,aes(x=Var1,y=Var2,fill=value)) + geom_tile()
# -------------------------------------
# AGE - NUMERIC
hist(all_bd$age)
boxplot(all_bd$age)
# DURATION - NUMERIC
hist(log(all_bd$duration))
boxplot(log(all_bd$duration))
# -------------------------------
# CAMPAIGN - CATEGORICAL
sort(table(all_bd$campaign),decreasing = T)
all_bd = CreateDummies(all_bd,"campaign",100)
# PDAYS - CAETGORICAL
sort(table(all_bd$pdays),decreasing = T)
all_bd = CreateDummies(all_bd,"pdays",100)
# PREVIOUS - CATEGORICAL
sort(table(all_bd$previous),decreasing = T)
all_bd = CreateDummies(all_bd,"previous",100)
# -------------------------------------
# -----------------------------------
# TARGET VARIABLE "Y"
all_bd$y = as.numeric(all_bd$y=="yes")
all_bd$y = as.factor(all_bd$y)
# -----------------------------------
# PREPARED TRAINING DATASET
bd_train = all_bd[which(all_bd$data=="train"),]
View(bd_train)
bd_train = bd_train %>% select(-data)
View(bd_train)
# PREPARED TEST DATASET
bd_test = all_bd[which(all_bd=="test"),]
View(bd_test)
View(all_bd)
View(all_bd)
View(bdtr)
View(bdts)
View(bd_train)
View(bd_test)
View(bd_test)
# PREPARED TEST DATASET
bd_test = all_bd[which(all_bd$data=="test"),]
View(bd_test)
bd_test = bd_test %>% select(-data)
View(bd_test)
pred<-as.data.frame(round(predict(final_model,
newdata = bd_test[-y],
type = "prob")[,2]))
pred<-as.data.frame(round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2]))
View(pred)
roc(y,pred)
roc(bd_test$y,pred)
View(pred)
pred<-as.data.frame("y"=round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2]))
pred<-round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2])
pred
roc(bd_test$y,pred)
confusionMatrix(pred,bd_test$y)
confusionMatrix(as.factor(pred),bd_test$y)
train.score=predict(final_model,newdata = bd_train,type='response')
real=bd_train$y
cutoffs=seq(0.001,0.999,0.001)
cutoff_data=data.frame(cutoff=99,Sn=99,Sp=99,KS=99,F5=99,F.1=99,M=99)
for(cutoff in cutoffs){
predicted=as.numeric(train.score>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=TN+FP
Sn=TP/P
Sp=TN/N
precision=TP/(TP+FP)
recall=Sn
KS=(TP/P)-(FP/N)
F5=(26*precision*recall)/((25*precision)+recall)
F.1=(1.01*precision*recall)/((.01*precision)+recall)
M=(4*FP+FN)/(5*(P+N))
cutoff_data=rbind(cutoff_data,c(cutoff,Sn,Sp,KS,F5,F.1,M))
}
cutoff_data=cutoff_data[-1,]
#### visualise how these measures move across cutoffs
ggplot(cutoff_data,aes(x=cutoff,y=Sp))+geom_line()
cutoff_long=cutoff_data %>%
gather(Measure,Value,Sn:M)
ggplot(cutoff_long,aes(x=cutoff,y=Value,color=Measure))+geom_line()
my_cutoff=cutoff_data$cutoff[which.max(cutoff_data$KS)]
my_cutoff
train.score
real=bd_train$y
real
cutoffs=seq(0.001,0.999,0.001)
cutoffs
cutoff_data=data.frame(cutoff=99,Sn=99,Sp=99,KS=99,F5=99,F.1=99,M=99)
cutoff_data
for(cutoff in cutoffs){
predicted=as.numeric(train.score>cutoff)
print(predicted)
TP=sum(real==1 & predicted==1)
print(TP)
TN=sum(real==0 & predicted==0)
print(TN)
FP=sum(real==0 & predicted==1)
print(FP)
FN=sum(real==1 & predicted==0)
print(FN)
P=TP+FN
N=TN+FP
Sn=TP/P
Sp=TN/N
precision=TP/(TP+FP)
recall=Sn
KS=(TP/P)-(FP/N)
F5=(26*precision*recall)/((25*precision)+recall)
F.1=(1.01*precision*recall)/((.01*precision)+recall)
M=(4*FP+FN)/(5*(P+N))
cutoff_data=rbind(cutoff_data,c(cutoff,Sn,Sp,KS,F5,F.1,M))
}
confusionMatrix(as.factor(pred),bd_test$y)
save.image("E:/edvancer/business_analytics/r_programming/upgrad/bank-additional/.RData")
pred_df <- as.data.frame(pred)
View(pred_df)
names(pred_df$pred) <- "y"
names(pred_df$pred) <- "y"
View(pred_df)
names(pred_df[1]) <- "y"
names(pred_df)
names(pred_df) <- "y"
View(pred_df)
save.image("E:/edvancer/business_analytics/r_programming/upgrad/bank-additional/.RData")
View(bd_train)
roc(bd_test$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
final_model <- randomForest(y~.,
data = bd_train,
mtry = 35,
ntree = 700,
maxnodes = 100,
nodesize = 10,
do.trace = T)
final_model
pred<-round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2])
pred
pred_df <- as.data.frame(pred)
names(pred_df) <- "y"
write.csv(final_rf_pred,"submission.csv",
row.names = F)
roc(bd_test$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
final_model <- randomForest(y~.,
data = bd_train,
mtry = 35,
ntree = 700,
maxnodes = 100,
nodesize = 15,
do.trace = T)
final_model
pred<-round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2])
roc(bd_test$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
final_model <- randomForest(y~.,
data = bd_train,
mtry = 35,
ntree = 700,
maxnodes = 100,
nodesize = 20,
do.trace = T)
final_model
pred<-round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2])
pred
pred_df <- as.data.frame(pred)
names(pred_df) <- "y"
roc(bd_test$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
pROC::auc(bd_test$y,pred)
plot(pROC::auc(bd_test$y,pred))
final_model <- randomForest(y~.,
data = bd_train,
mtry = 25,
ntree = 700,
maxnodes = 100,
nodesize = 20,
do.trace = T)
pred<-round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2])
roc(bd_test$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
pROC::auc(bd_test$y,pred)
final_model <- randomForest(y~.,
data = bd_train,
mtry = 40,
ntree = 700,
maxnodes = 100,
nodesize = 20,
do.trace = T)
View(all_bd)
# -------------------------------------
all_bd<-all_bd %>%
mutate(age=as.numeric(scale(all_bd$age)),
duration=as.numeric(scale(all_bd$duration)),
emp.var.rate=as.numeric(scale(all_bd$emp.var.rate)),
cons.price.idx=as.numeric(scale(all_bd$cons.price.idx)),
cons.conf.idx=as.numeric(scale(all_bd$cons.conf.idx)),
euribor3m=as.numeric(scale(all_bd$euribor3m)),
nr.employed=as.numeric(scale(all_bd$nr.employed)))
# PREPARED TRAINING DATASET
bd_train = all_bd[which(all_bd$data=="train"),]
View(bd_train)
bd_train = bd_train %>% select(-data)
View(bd_train)
# PREPARED TEST DATASET
bd_test = all_bd[which(all_bd$data=="test"),]
View(bd_test)
bd_test = bd_test %>% select(-data)
final_model <- randomForest(y~.,
data = bd_train,
mtry = 40,
ntree = 700,
maxnodes = 100,
nodesize = 20,
do.trace = T)
final_model
pred<-round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2])
pred
roc(bd_test$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
save.image("E:/edvancer/business_analytics/r_programming/upgrad/bank-additional/.RData")
pred<-round(predict(final_model,
newdata = bd_train[-8],
type = "prob")[,2])
pred
roc(bd_train$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
pROC::auc(bd_test$y,pred)
confusionMatrix(as.factor(pred),bd_train$y)
pROC::auc(bd_train$y,pred)
final_model <- randomForest(y~.,
data = bd_train,
mtry = 40,
ntree = 500,
maxnodes = 100,
nodesize = 5,
do.trace = T)
final_model
pred<-round(predict(final_model,
newdata = bd_train[-8],
type = "prob")[,2])
pred
roc(bd_train$y,pred)
confusionMatrix(as.factor(pred),bd_train$y)
pROC::auc(bd_train$y,pred)
library(car)
lm(y~.,data=bd_train)
for_vif = lm(y~.,data=bd_train)
sort(vif(for_vif),decreasing = T)
for_vif = lm(as.numeric(y)~.,data=bd_train)
sort(vif(for_vif),decreasing = T)
for_vif
rm(for_vif)
pred<-round(predict(final_model,
newdata = bd_test[-8],
type = "prob")[,2])
pred
pred_df <- as.data.frame(pred)
roc(bd_train$y,pred)
confusionMatrix(as.factor(pred),bd_test$y)
pROC::auc(bd_test$y,pred)
